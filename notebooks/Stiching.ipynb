{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "b49c50da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import norm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "ab135e7f-4ca2-48f7-b38c-13d24dea3d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select the mode of panoptic: 1 for DETR, 2 for SETR:  1\n"
     ]
    }
   ],
   "source": [
    "#select the mode of panoptic\n",
    "#set the path of picture/mask/label\n",
    "panoptic_mode = int(input(\"Select the mode of panoptic: 1 for DETR, 2 for SETR: \"))\n",
    "if panoptic_mode == 1:\n",
    "    Filepath = './DETR_result/'\n",
    "    image1 = cv2.imread('image1.jpg')\n",
    "    image2 = cv2.imread('image2.jpg')\n",
    "    mask_label_path1 = Filepath + 'image1/'\n",
    "    mask_label_path2 = Filepath + 'image2/'\n",
    "    \n",
    "elif panoptic_mode == 2:\n",
    "    Filepath = './SETR_result/'\n",
    "    image1 = cv2.imread('image1.jpg')\n",
    "    image2 = cv2.imread('image2.jpg')\n",
    "    mask_label_path1 = Filepath + 'image1/'\n",
    "    mask_label_path2 = Filepath + 'image2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "1f9db5f7-edb3-4102-b0d0-aa1cd21da036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary to store the mask and label and category\n",
    "def read_masks_and_labels(mask_label_path):\n",
    "    labels = []\n",
    "    categories = []\n",
    "\n",
    "    with open(mask_label_path + 'image_categories.txt', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            parts = line.strip().split(',')\n",
    "            label = parts[0].split(':')[1].strip()\n",
    "            category = parts[1].split(':')[1].strip()\n",
    "            labels.append(int(label))\n",
    "            categories.append(category)\n",
    "\n",
    "    masks = []\n",
    "    mask_dict = {}\n",
    "    \n",
    "    for i, ID in enumerate (labels):\n",
    "        filename = 'mask_class_' + str(ID) + '.png'\n",
    "        mask = cv2.imread(mask_label_path + filename, cv2.IMREAD_GRAYSCALE)\n",
    "        masks = np.array(mask)\n",
    "        mask_dict[i] = {'labels': labels[i], 'categories': categories[i], 'masks': masks}\n",
    "        \n",
    "    return mask_dict\n",
    "\n",
    "# Use the function to read masks and labels\n",
    "mask_dict1 = read_masks_and_labels(mask_label_path1)\n",
    "mask_dict2 = read_masks_and_labels(mask_label_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "91bbf934-b6a1-477c-82a7-7ddb59d969da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(mask_dict1)\n",
    "# print(mask_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "de4ca25e-7b14-410f-8e1e-f1c8b8674537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_from_dict(mask_dict):\n",
    "    ids = set()\n",
    "    for i in range(len(mask_dict)):\n",
    "        ids.add(mask_dict[i]['labels'])\n",
    "    return ids\n",
    "\n",
    "def invert_intersection_masks(modified_dict):\n",
    "    # Stack and invert masks for the intersection\n",
    "    if len(modified_dict) > 0:\n",
    "        intersection_label = 99\n",
    "        intersection_masks = np.stack([item['masks'] for item in modified_dict.values()])\n",
    "        intersection_mask = np.bitwise_not(np.bitwise_or.reduce(intersection_masks, axis=0))\n",
    "        modified_dict[len(modified_dict)] = {\n",
    "            'labels': intersection_label,\n",
    "            'categories': 'others',\n",
    "            'masks': intersection_mask\n",
    "        } \n",
    "    return modified_dict\n",
    "\n",
    "def modified_dict_by_class(mask_dict1, mask_dict2):\n",
    "    # Create sets to store the IDs of each dictionary\n",
    "    ids_dict1 = get_id_from_dict(mask_dict1)\n",
    "    ids_dict2 = get_id_from_dict(mask_dict2)\n",
    "\n",
    "    # print(ids_dict1)\n",
    "    # print(ids_dict2)\n",
    "    \n",
    "    # Create dictionaries to store matched and unmatched items\n",
    "    same_dict1 = {}\n",
    "    same_dict2 = {}\n",
    "    counter1 = 0\n",
    "    counter2 = 0\n",
    "    \n",
    "    # Process the first dictionary\n",
    "    for key in mask_dict1:\n",
    "        if mask_dict1[key]['labels'] in ids_dict2:\n",
    "            same_dict1[counter1] = mask_dict1[key]\n",
    "            counter1+=1\n",
    "    \n",
    "    # Process the second dictionary\n",
    "    for key in mask_dict2:\n",
    "        if mask_dict2[key]['labels'] in ids_dict1:\n",
    "            same_dict2[counter2] = mask_dict2[key]\n",
    "            counter2+=1\n",
    "\n",
    "    modified_dict1 = {}\n",
    "    modified_dict2 = {}\n",
    "\n",
    "    modified_dict1 = invert_intersection_masks(same_dict1)\n",
    "    modified_dict2 = invert_intersection_masks(same_dict2)\n",
    "  \n",
    "    return modified_dict1, modified_dict2\n",
    "\n",
    "modified_dict1, modified_dict2 = modified_dict_by_class(mask_dict1, mask_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "97d504e6-7675-460b-95bb-5134160f2561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(modified_dict1)\n",
    "# print(modified_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "606e834b-1f2a-499f-b421-153298558027",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SIFT\n",
    "#create the feature point\n",
    "# Convert images to grayscale\n",
    "gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "4d2eab36-3f49-4eb0-ba41-0291cde56c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(gray, mask):\n",
    "    mask = cv2.resize(mask, (gray.shape[1], gray.shape[0]))\n",
    "\n",
    "    gray_array = np.array(gray)\n",
    "    mask_array = np.array(mask)\n",
    "\n",
    "    # Ensure the mask is binary (i.e., contains only 0s and 1s)\n",
    "    binary_mask = (mask_array > 0).astype(np.uint8)\n",
    "\n",
    "    # Perform dilation on the binary mask\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    dilated_mask = cv2.dilate(binary_mask, kernel, iterations=5)\n",
    "\n",
    "    # Use the mask to crop the grayscale image\n",
    "    cropped_gray = gray_array * dilated_mask\n",
    "\n",
    "    # Convert the cropped result back to an image\n",
    "    cropped_gray_image = Image.fromarray(cropped_gray)\n",
    "    \n",
    "    return cropped_gray_image\n",
    "\n",
    "\n",
    "def process_images_and_store(gray, mask_dict):\n",
    "    # Create a dictionary to store the processed images and their categories\n",
    "    processed_images = {}\n",
    "\n",
    "    # Loop over each mask in the mask dictionary\n",
    "    for i in range(len(mask_dict)):\n",
    "        # Process the image\n",
    "        processed_image = process_image(gray, mask_dict[i]['masks'])\n",
    "        processed_image = np.array(processed_image)\n",
    "        \n",
    "        # Get the category for this image\n",
    "        category = mask_dict[i]['categories']\n",
    "        \n",
    "        # Get the label for this image\n",
    "        label = mask_dict[i]['labels']\n",
    "        \n",
    "        # Save the processed image and its category to the dictionary\n",
    "        processed_images[i] = {'label': label, 'category': category, 'image': processed_image}\n",
    "    \n",
    "    return processed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "e7afa597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function to process the images and store them in dictionaries\n",
    "processed_images1 = process_images_and_store(gray1, modified_dict1)\n",
    "processed_images2 = process_images_and_store(gray2, modified_dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "62f33f7a-dc97-4064-aef1-c09ef9384e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(processed_images1[0]['image'], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "7d8ab746-6556-4146-b0d6-a3e2b439db82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(processed_images1[1]['image'], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "95f20591-4a87-41a8-96ee-63d6fbc12bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(processed_images1[2]['image'], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "d5fc7fb4-d26d-4e93-b561-6e2a0b067080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[145, 142, 128, ...,  99,  74,  89],\n",
       "       [153, 134, 118, ..., 101,  84, 106],\n",
       "       [140, 140, 132, ..., 110,  97,  95],\n",
       "       ...,\n",
       "       [ 19,  19,  17, ..., 162, 160, 162],\n",
       "       [ 17,  22,  18, ..., 180, 176, 162],\n",
       "       [ 14,  24,  19, ..., 169, 164, 156]], dtype=uint8)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_images1[2]['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "da7894a7-fe88-44ba-90e1-868d8883b49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[145, 142, 128, ...,  99,  74,  89],\n",
       "       [153, 134, 118, ..., 101,  84, 106],\n",
       "       [140, 140, 132, ..., 110,  97,  95],\n",
       "       ...,\n",
       "       [ 19,  19,  17, ..., 162, 160, 162],\n",
       "       [ 17,  22,  18, ..., 180, 176, 162],\n",
       "       [ 14,  24,  19, ..., 169, 164, 156]], dtype=uint8)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9de2be13-b9b5-46ac-b87c-da526835535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the same label mask to seperate the picture's feature point\n",
    "# Initialize the feature detector and extractor (e.g., SIFT)\n",
    "sift = cv2.SIFT_create()\n",
    "# Detect keypoints and compute descriptors for both images\n",
    "keypoints1, descriptors1 = sift.detectAndCompute(gray1, None)\n",
    "keypoints2, descriptors2 = sift.detectAndCompute(gray2, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56eef699-04f1-43f3-8c96-f2cf4eaa98c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#matching each label picture\n",
    "# Initialize the feature matcher using brute-force matching\n",
    "bf = cv2.BFMatcher()\n",
    "\n",
    "# Match the descriptors using brute-force matching\n",
    "matches = bf.match(descriptors1, descriptors2)\n",
    "\n",
    "# Select the top N matches\n",
    "num_matches = 50\n",
    "matches = sorted(matches, key=lambda x: x.distance)[:num_matches]\n",
    "\n",
    "# Extract matching keypoints\n",
    "src_points = np.float32([keypoints1[match.queryIdx].pt for match in matches]).reshape(-1, 1, 2)\n",
    "dst_points = np.float32([keypoints2[match.trainIdx].pt for match in matches]).reshape(-1, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcccc6f3-da3f-4f83-ab20-ccc5dd743fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary all the matching into one picture \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25d5fec5-1b14-404a-a6d5-d6d34e69f9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the homography matrix\n",
    "homography, _ = cv2.findHomography(src_points, dst_points, cv2.RANSAC, 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87e3456-bd8e-4f2f-a1d1-5830041c76d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warp the first image using the homography\n",
    "result = cv2.warpPerspective(image1, homography, (image2.shape[1], image2.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e40ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blending the warped image with the second image using alpha blending\n",
    "alpha = 0.5  # blending factor\n",
    "blended_image = cv2.addWeighted(result, alpha, image2, 1 - alpha, 0)\n",
    "\n",
    "# Display the blended image\n",
    "cv2.imshow('Blended Image', blended_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
